for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
#plot(density(sharp.null.hypothesis),  main = paste('Samp: ', sample_size, ' ATE: ', round(ATE, 3),
#                                                   'p-value :', round(p_value, 3)), cex.main= 0.8,
#     xlab=column)
#abline(v = ATE, col = "blue")
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
print("")
}
print('=====================================
=')
}
str(d)
mean(d$Duration..in.seconds.)
mean(as.numerical(d$Duration..in.seconds.))
mean(as.numeric(d$Duration..in.seconds.))
View(d)
as.numeric(d$Duration..in.seconds.)
d$Duration..in.seconds.
mean(as.numeric(as.characterd$Duration..in.seconds.))
mean(as.numeric(as.character(d$Duration..in.seconds.)))
7.25/60
0.12 * 3,38
0.12 * 3.38
hist(d$Duration..in.seconds.)
hist(as.numeric(as.character(d$Duration..in.seconds.)))
str(d)
for (image in images[1]){
for (question in questions[1]){
column <- paste(image, question, sep = "")
sd(d[[column]])
}
}
print(sd(d[[column]]))
column
?sd
sd(d[[column]], na.rm = TRUE)
z = 1.96
E = 1
2**4
2**1000
2**100000000
for (image in images[1]){
for (question in questions[1]){
column <- paste(image, question, sep = "")
s_d <- sd(d[[column]], na.rm = TRUE)
n <- (z * s_d / E)**2
n
}
}
for (image in images[1]){
for (question in questions[1]){
column <- paste(image, question, sep = "")
s_d <- sd(d[[column]], na.rm = TRUE)
n <- (z * s_d / E)**2
print(n)
}
}
z * s_d
E = 0.1
for (image in images[1]){
for (question in questions[1]){
column <- paste(image, question, sep = "")
s_d <- sd(d[[column]], na.rm = TRUE)
n <- (z * s_d / E)**2
print(n)
}
}
E = 0.05
for (image in images[1]){
for (question in questions[1]){
column <- paste(image, question, sep = "")
s_d <- sd(d[[column]], na.rm = TRUE)
n <- (z * s_d / E)**2
print(n)
}
}
E = 0.01
for (image in images[1]){
for (question in questions[1]){
column <- paste(image, question, sep = "")
s_d <- sd(d[[column]], na.rm = TRUE)
n <- (z * s_d / E)**2
print(n)
}
}
E = 0.05
for (image in images[1]){
for (question in questions[1]){
column <- paste(image, question, sep = "")
s_d <- sd(d[[column]], na.rm = TRUE)
n <- (z * s_d / E)**2
print(n)
}
}
for (image in images[1]){
for (question in questions[1]){
column <- paste(image, question, sep = "")
s_d <- sd(d[[column]], na.rm = TRUE)
n <- (z * s_d / E)**2
print(column)
print(paste('sample_size :', n))
}
}
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
s_d <- sd(d[[column]], na.rm = TRUE)
n <- (z * s_d / E)**2
print(column)
print(paste('sample_size :', n))
}
}
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
s_d <- sd(d[[column]], na.rm = TRUE)
n <- (z * s_d / E)**2
print(column)
print(paste('sample_size :', round(n, 0)))
}
}
true_population <- c(rep(0, pop * (1/2)), rep(1, pop * (1/2)))
mean(true_population)
# Rely on simulated CLT to get the distribution of the ATE
sharp.null.hypothesis <- replicate(10000, mean(sample(true_population, sample_size)) - mean(sample(true_population, sample_size)))
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
#plot(density(sharp.null.hypothesis),  main = paste('Samp: ', sample_size, ' ATE: ', round(ATE, 3),
#                                                   'p-value :', round(p_value, 3)), cex.main= 0.8,
#     xlab=column)
#abline(v = ATE, col = "blue")
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
print("")
}
print('======================================')
}
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
#plot(density(sharp.null.hypothesis),  main = paste('Samp: ', sample_size, ' ATE: ', round(ATE, 3),
#                                                   'p-value :', round(p_value, 3)), cex.main= 0.8,
#     xlab=column)
#abline(v = ATE, col = "blue")
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
}
print('======================================')
}
images <- c('Passion', 'Coffee', 'Couple', 'Work', 'Fit')
questions <- c('_i_identify_', '_i_prefer_', '_o_prefer_', '_validate_')
column <- 'Passion_i_identify_'
pop <- 100000
sample_size <- 400
true_population <- c(rep(0, pop * (1/2)), rep(1, pop * (1/2)))
mean(true_population)
# Rely on simulated CLT to get the distribution of the ATE
sharp.null.hypothesis <- replicate(10000, mean(sample(true_population, sample_size)) - mean(sample(true_population, sample_size)))
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
#plot(density(sharp.null.hypothesis),  main = paste('Samp: ', sample_size, ' ATE: ', round(ATE, 3),
#                                                   'p-value :', round(p_value, 3)), cex.main= 0.8,
#     xlab=column)
#abline(v = ATE, col = "blue")
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
}
print('======================================')
}
plot(density(sharp.null.hypothesis),  main = paste('Samp: ', sample_size, ' ATE: ', round(ATE, 3),
'p-value :', round(p_value, 3)), cex.main= 0.8)
par(mfrow=c(1,1))
plot(density(sharp.null.hypothesis),  main = paste('Samp: ', sample_size, ' ATE: ', round(ATE, 3),
'p-value :', round(p_value, 3)), cex.main= 0.8)
plot(density(sharp.null.hypothesis),  main = paste('Samp: ', sample_size), cex.main= 0.8)
plot(density(sharp.null.hypothesis),  main = paste('Sample_size: ', sample_size), cex.main= 0.8)
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
abline(v = ATE, col = "blue")
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
}
print('======================================')
}
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
if (p-value < 0.05){
abline(v = abs(ATE), col = "blue")
} else {
abline(v = abs(ATE), col = "red")
}
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
}
print('======================================')
}
par(mfrow=c(1,1))
plot(density(sharp.null.hypothesis),  main = paste('Sample_size: ', sample_size), cex.main= 0.8)
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
if (p_value < 0.05){
abline(v = abs(ATE), col = "blue")
} else {
abline(v = abs(ATE), col = "red")
}
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
}
print('======================================')
}
sample_size <- 30
true_population <- c(rep(0, pop * (1/2)), rep(1, pop * (1/2)))
mean(true_population)
# Rely on simulated CLT to get the distribution of the ATE
sharp.null.hypothesis <- replicate(10000, mean(sample(true_population, sample_size)) - mean(sample(true_population, sample_size)))
par(mfrow=c(1,1))
plot(density(sharp.null.hypothesis),  main = paste('Sample_size: ', sample_size), cex.main= 0.8)
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
if (p_value < 0.05){
abline(v = abs(ATE), col = "blue")
} else {
abline(v = abs(ATE), col = "red")
}
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
}
print('======================================')
}
sample_size <- 400
true_population <- c(rep(0, pop * (1/2)), rep(1, pop * (1/2)))
mean(true_population)
# Rely on simulated CLT to get the distribution of the ATE
sharp.null.hypothesis <- replicate(10000, mean(sample(true_population, sample_size)) - mean(sample(true_population, sample_size)))
par(mfrow=c(1,1))
plot(density(sharp.null.hypothesis),  main = paste('Sample_size: ', sample_size), cex.main= 0.8)
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
if (p_value < 0.05){
abline(v = abs(ATE), col = "blue")
} else {
abline(v = abs(ATE), col = "red")
}
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
}
print('======================================')
}
sample_size <- 500
true_population <- c(rep(0, pop * (1/2)), rep(1, pop * (1/2)))
mean(true_population)
# Rely on simulated CLT to get the distribution of the ATE
sharp.null.hypothesis <- replicate(10000, mean(sample(true_population, sample_size)) - mean(sample(true_population, sample_size)))
par(mfrow=c(1,1))
plot(density(sharp.null.hypothesis),  main = paste('Sample_size: ', sample_size), cex.main= 0.8)
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
if (p_value < 0.05){
abline(v = abs(ATE), col = "blue")
} else {
abline(v = abs(ATE), col = "red")
}
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
}
print('======================================')
}
sample_size <- 400
true_population <- c(rep(0, pop * (1/2)), rep(1, pop * (1/2)))
mean(true_population)
# Rely on simulated CLT to get the distribution of the ATE
sharp.null.hypothesis <- replicate(10000, mean(sample(true_population, sample_size)) - mean(sample(true_population, sample_size)))
par(mfrow=c(1,1))
plot(density(sharp.null.hypothesis),  main = paste('Sample_size: ', sample_size), cex.main= 0.8)
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
if (p_value < 0.05){
abline(v = abs(ATE), col = "blue")
} else {
abline(v = abs(ATE), col = "red")
}
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
}
print('======================================')
}
print(column)
for (column in columns_to_analyse[1]){
print(column)
}
d[[column]]
length(d[[column]])
control_treatment <- c(rep(1, length(d[[column]]) * (1/2)), rep(0, length(d[[column]]) * (1/2)))
control_treatment
sample(control_treatment, length(d[[column]])
for (column in columns_to_analyse[1]){
print(column)
length(d[[column]])
d[[column]]
}
######## Getting the ATE for IMAGES questions #########
images <- c('Passion', 'Coffee', 'Couple', 'Work', 'Fit')
questions <- c('_i_identify_', '_i_prefer_', '_o_prefer_', '_validate_')
column <- 'Passion_i_identify_'
pop <- 100000
sample_size <- 400
true_population <- c(rep(0, pop * (1/2)), rep(1, pop * (1/2)))
mean(true_population)
# Rely on simulated CLT to get the distribution of the ATE
sharp.null.hypothesis <- replicate(10000, mean(sample(true_population, sample_size)) - mean(sample(true_population, sample_size)))
par(mfrow=c(1,1))
plot(density(sharp.null.hypothesis),  main = paste('Sample_size: ', sample_size), cex.main= 0.8)
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
ATE <- get_ATE(d, column)
p_value <- mean(abs(ATE) <= sharp.null.hypothesis)
print(column)
print(paste('ATE:', ATE))
print(paste('p-value: ', p_value, ifelse(p_value < 0.05, '***', ''), sep = ""))
if (p_value < 0.05){
abline(v = abs(ATE), col = "blue")
} else {
abline(v = abs(ATE), col = "red")
}
percentage_similar <- sum(d[[column]], na.rm = TRUE)/nrow(d[!is.na(d[[column]]),])
print(paste('percentage_similar: ', round(percentage_similar,2)))
}
print('======================================')
}
#Doing the analysis for all images per user - instead of one by one
#With n=30 - none of the results are significant except for couple_o_prefer -> but this results can be
# considered as a fishing expedition results...
#Divergence of opinion
######## Running the formula for sample size ########
#https://www.isixsigma.com/tools-templates/sampling-data/how-determine-sample-size-determining-sample-size/
z = 1.96
E = 0.05 #For a 5% effect size
for (image in images){
for (question in questions){
column <- paste(image, question, sep = "")
s_d <- sd(d[[column]], na.rm = TRUE)
n <- (z * s_d / E)**2
print(column)
print(paste('sample_size :', round(n, 0)))
}
}
sample(control_treatment, length(d[[column]]))
mean(sample(control_treatment, length(d[[column]])))
d[[column]]
print(column)
length(d[[column]])
d[[column]]
for (column in columns_to_analyse[1]){
print(column)
length(d[[column]])
d[[column]]
}
d[[column]]
sample(control_treatment, length(d[[column]]))
assign
assignment <- sample(control_treatment, length(d[[column]]))
d <- data.frame(outcome = d[[column]], assignement = assignment)
View(d)
dt <- data.frame(outcome = d[[column]], assignement = assignment)
# Create a summary table
setwd('/Users/ozimmer/GoogleDrive/berkeley/w241/BeatuyAd_CausalExperiment')
d <- read.csv('BeautyAds_July 6, 2017_17.33.csv')
# Filter out irrelavant entries
d <- d[-c(1,2),]
d <- d[d$Status == 'IP Address',] #Remove survey preview
d <- d[d$Welcome == 'I agree',] #Remove users who didn't agree to participate
d <- d[d$Finished == 'True',] #Remove users who didn't finisn the survey
d <- d[d$Group %in% c('Treatment', 'Control'),]
# Recoding of values
recode_values <- function(d, column){
d[[column]] <- as.character(d[[column]])
d[[column]] <- recode(d[[column]], 'Strongly disagree' = -2,
'Disagree' = -1, 'Agree' = 1, 'Strongly agree' = 2,
.missing = 0, .default = 0)
}
columns_to_analyse <- c('Personal_Views_Confident', 'Personal_Views_Beautiful',
'Personal_Views_Beauty_Importance', 'Personal_Views_Relate_To_Model')
for (column in columns_to_analyse){
d[[column]] <- recode_values(d, column)
}
# Correct column names misspellings
d <- rename(d, Coffee_validate_1 = Coffe_validate_1,
Fit_i_identify_1 = FIt_i_identify_1,
Work_i_identify_2 = work_i_identify_2)
# Combine and recode randomization 1 & 2 for the images
images <- c('Passion', 'Coffee', 'Couple', 'Work', 'Fit')
questions <- c('_i_identify_', '_i_prefer_', '_o_prefer_', '_validate_')
randomization <- c('1', '2')
for (image in images){
for (question in questions){
column1 <- paste(image, question, '1', sep = "")
d[[column1]] <- ifelse(d[[column1]] == 'Ad 1', 2, ifelse(d[[column1]] == 'Ad 2', 1, 0))
column2 <- paste(image, question, '2', sep = "")
d[[column2]] <- ifelse(d[[column2]] == 'Ad 2', 2, ifelse(d[[column2]] == 'Ad 1', 1, 0))
new_column <- paste(image, question, sep ="")
d[[new_column]] <- d[[column1]] + d[[column2]] - 1
d[[new_column]] <- ifelse(d[[new_column]] == -1, NA, d[[new_column]])
}
}
dt <- data.frame(outcome = d[[column]], assignement = assignment)
View(dt)
null.ATE <- mean(dt[assignment == 1, ]$outcome) - mean(dt[assignment == 0, ]$outcome)
replicate(10, mean(sample(true_population, sample_size)) - mean(sample(true_population, sample_size)))
get_null_ATE_from_current_sample <- function(d, control_treatment, column){
assignment <- sample(control_treatment, length(d[[column]]))
dt <- data.frame(outcome = d[[column]], assignement = assignment)
null.ATE <- mean(dt[assignment == 1, ]$outcome) - mean(dt[assignment == 0, ]$outcome)
return(null.ATE)
}
for (column in columns_to_analyse[1]){
sharp.null.hypothesis <- replicate(10000, get_null_ATE_from_current_sample(d, control_treatment, column))
}
for (column in columns_to_analyse[1]){
sharp.null.hypothesis <- replicate(10000, get_null_ATE_from_current_sample(d, control_treatment, column))
ATE <- get_ATE(d, column)
p_value <- mean(ATE <= sharp.null.hypothesis)
plot(density(sharp.null.hypothesis),  main = paste('Sample_size: ', sample_size), cex.main= 0.8)
abline(v = ATE, col = "blue")
}
sample_size <- length(d[[column]])
par(mfrow=c(1,1))
for (column in columns_to_analyse[1]){
sharp.null.hypothesis <- replicate(10000, get_null_ATE_from_current_sample(d, control_treatment, column))
ATE <- get_ATE(d, column)
p_value <- mean(ATE <= sharp.null.hypothesis)
plot(density(sharp.null.hypothesis),  main = paste('Samp: ', sample_size, ' ATE: ', round(ATE, 3),
'p-value :', round(p_value, 3)), cex.main= 0.8,
xlab=column)
abline(v = ATE, col = "blue")
}
par(mfrow=c(2,2))
for (column in columns_to_analyse){
sharp.null.hypothesis <- replicate(10000, get_null_ATE_from_current_sample(d, control_treatment, column))
ATE <- get_ATE(d, column)
p_value <- mean(ATE <= sharp.null.hypothesis)
plot(density(sharp.null.hypothesis),  main = paste('Samp: ', sample_size, ' ATE: ', round(ATE, 3),
'p-value :', round(p_value, 3)), cex.main= 0.8,
xlab=column)
abline(v = ATE, col = "blue")
}
